{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 1, MSBC.5190 Modern Artificial Intelligence S24\n",
        "\n",
        "**Teammates: A, B, C**\n",
        "\n",
        "**Teamname: XX**\n",
        "\n",
        "Handout 02/16/2023 5pm, **due 03/01/2023 by 5pm**. Please submit through Canvas. Each team only needs to submit one copy.\n",
        "\n",
        "Important information about submission:\n",
        "- Write all code, text (answers), and figures in the notebook.\n",
        "- Please make sure that the submitted notebook has been run and the cell outputs are visible.\n",
        "- Please print the notebook as PDF and submit it together with the notebook. Your submission should contain two files: `homework1-teamname.ipynb` and `homework1-teamname.pdf`\n",
        "\n",
        "In this homework, we will build and train convolutional neural networks (CNN) on a subset of [Kaggle \"cats vs. dog\"](https://www.kaggle.com/c/dogs-vs-cats) classification data. The goal of the homework are four folds:\n",
        "\n",
        "\n",
        "1.   Train a small CNN from scratch as a baseline\n",
        "2.   Improve the baseline model. You can find some hints in the last section.\n",
        "3.   Implement transfer learning: fine-tune top layers of a pre-trained network\n",
        "4.   Experiment and develop a better model (i.e., better accuracy). You can find some hints in the last section."
      ],
      "metadata": {
        "id": "CReTLT9gZZBi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, import the packages or modules required for this homework."
      ],
      "metadata": {
        "id": "zE0gwmvro7l8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "# TODO: Fill in your codes                                                     #\n",
        "# Import packages or modules                                                   #\n",
        "################################################################################"
      ],
      "metadata": {
        "id": "2Ju3_EJHDU4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Obtain and Organize the Data Sets\n",
        "\n",
        "The competition data is divided into training set (25,000 images) and testing set (10,000 images). For this homework, we are going to use 4,000 images (2,000 cat images and 2,000 dog images) from the original training data for training, 1,000 images for validation, and 1,000 images for testing.\n",
        "\n",
        "\n",
        "### Download the Data Set###\n",
        "The small data set `dogs-vs-cats-small.zip` can be downloaded through Canvas. After downloading the data, upload it to Google Colab. The easiest way to do it is to use the upload option at the top of the file-explorer pane. Note that files uploaded in this way are uploaded to the running instance and will be deleted when the session is disconnected. Alternatively, you can also upload the data set to your Google Drive and mount your Google Drive to Colab. (More info: https://colab.research.google.com/notebooks/io.ipynb)\n"
      ],
      "metadata": {
        "id": "muJRiiu1hY4g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Unzip the Data Set###\n"
      ],
      "metadata": {
        "id": "huC0ZChevyi2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip ./dogs-vs-cats-small.zip"
      ],
      "metadata": {
        "id": "JzO-bHZOn23a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, I assume that you upload `dogs-vs-cats-small.zip` to the running instance of Google Colab. I have already organized the data to training, validation, and testing dataset. Under each of the data directories, each subdirectory represent a class and contains images from that class. After unzipping, you will find the training, validation, and testing data set in the following paths:\n",
        "\n",
        "* dogs-vs-cats-small/\n",
        "  * train/\n",
        "    * cat/\n",
        "    * dog/\n",
        "  * validation/\n",
        "    * cat/\n",
        "    * dog/\n",
        "  *test/\n",
        "    * cat/\n",
        "    * dog/\n"
      ],
      "metadata": {
        "id": "MlEEwiXRvsap"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read and Preprocess the Data\n",
        "\n",
        "We use [ImageDataGenerator](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator) to load images on the fly from disk. You can use and modify it later to perform random data augmentations to improve model performance. Here, we rescale the data to between 0 and 1 (by multiplying by 1/255)\n",
        "\n",
        "Note: Here we are following our textbook and use ImageDataGenerator to load images and perform data augmentation. Alternatively, you can also use tf.keras.utils.image_dataset_from_directory.\n",
        "\n",
        "*   https://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory\n",
        "*   https://www.tensorflow.org/tutorials/load_data/images\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vIMc-HIYp4rT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = './dogs-vs-cats-small/'"
      ],
      "metadata": {
        "id": "0SP17P88txs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "# Instantiate three image generator classes:\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255,\n",
        "    data_format='channels_last')\n",
        "\n",
        "valid_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255,\n",
        "    data_format='channels_last')\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255,\n",
        "    data_format='channels_last'\n",
        ")"
      ],
      "metadata": {
        "id": "EIn8h9JnWJ3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=32\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    directory=data_dir + 'train',\n",
        "    target_size=(224, 224),\n",
        "    classes=['cat','dog'],\n",
        "    class_mode='categorical',\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    seed=42)\n",
        "\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    directory=data_dir + 'validation',\n",
        "    target_size=(224, 224),\n",
        "    classes=['cat','dog'],\n",
        "    class_mode='categorical',\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    seed=42)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    directory=data_dir + 'test',\n",
        "    target_size=(224, 224),\n",
        "    classes=['cat','dog'],\n",
        "    class_mode='categorical',\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    seed=42)"
      ],
      "metadata": {
        "id": "Tf98roO5WVQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Build and Train a Baseline Model (40%)\n",
        "\n",
        "We will start with building a simple convolutional neural network.\n",
        "\n",
        "### Define the model\n",
        "\n",
        "Please define a model with the following layers and hyperparameters.\n",
        "* Input image: 224 (height) x 224 (width) x 3 (channels)\n",
        "* Convolution: 16 kernels (size = 3 x 3), stride = 1, padding = 1\n",
        "* MaxPool: kernel size = 2 x 2, stride = 2, padding = 0\n",
        "* Convolution: 32 kernels (size = 3 x 3), stride = 1, padding = 1\n",
        "* MaxPool: kernel size = 2 x 2, stride = 2, padding = 0\n",
        "* Convolution: 64 kernels (size = 3 x 3), stride = 1, padding = 1\n",
        "* MaxPool: kernel size = 2 x 2, stride = 2, padding = 0\n",
        "* Dense: 128 fully connected neurons\n",
        "* Output: 2 classes\n"
      ],
      "metadata": {
        "id": "jl4sglWa0iLr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "# TODO: Fill in your codes                                                     #\n",
        "# Define the model                                                             #\n",
        "################################################################################\n"
      ],
      "metadata": {
        "id": "8WRrDu32W371"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "-BvpdRmHXGwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inline Question #1:** Notice the output shape and # of param of each layer\n",
        "\n",
        "- What is the output shape of the first convolutional layer and how to calculate it?\n",
        "- What is the # of params of the first convolutional layer and how to calculate it?"
      ],
      "metadata": {
        "id": "2ChTTFUY9bAt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Your Answer:** *fill this in*"
      ],
      "metadata": {
        "id": "lxExVNSC-Cav"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configure and Train the Baseline Model\n",
        "\n",
        "Please use Adam as the optimizer and keep track of accuracy metric.\n",
        "\n",
        "**Inline Question #2:** What loss function will you choose for this classfication problem?"
      ],
      "metadata": {
        "id": "GY3ItH21-JVv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Your Answer:** *fill this in*"
      ],
      "metadata": {
        "id": "ZXe76ymH_Bg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "# TODO: Fill in your codes                                                     #\n",
        "# Configure and train the model (set number of epochs to 10)                   #\n",
        "################################################################################\n"
      ],
      "metadata": {
        "id": "JTkH28z5GlrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inline Question #3:** Please draw loss and accuracy learning curves on the training and validation set.\n",
        "- Please explain your observation of the learning curves."
      ],
      "metadata": {
        "id": "i53aZ5j-ZSmA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Your Answer:** *fill this in*"
      ],
      "metadata": {
        "id": "1gn8DKN4B8uU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "# TODO: Fill in your codes                                                     #\n",
        "# Draw learning curves                                                         #\n",
        "################################################################################"
      ],
      "metadata": {
        "id": "VKUx1wVsO_jx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate Model Performance\n",
        "\n",
        "**Inline Question #4:** What is the accuracy on the test dataset?"
      ],
      "metadata": {
        "id": "N6KUAJRJCHNr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Your Answer:** *fill this in*\n",
        "\n"
      ],
      "metadata": {
        "id": "NvVGmbWeCZDN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "# TODO: Fill in your codes                                                     #\n",
        "# Calculate accuracy on the test data set                                      #\n",
        "################################################################################\n"
      ],
      "metadata": {
        "id": "iktKmxDZaOjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Improve the Baseline Model (10%)\n",
        "\n",
        "**Inline Question #5:** Please propose and implement one improvement on the baseline model.\n",
        "* What is the rational for the proposed improvement?\n",
        "* Did it help? Please present your evidence."
      ],
      "metadata": {
        "id": "p1_7-yDzCk1U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Your Answer:** *fill this in*"
      ],
      "metadata": {
        "id": "99qcwGDkHfHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "# TODO: Fill in your codes                                                     #\n",
        "# You need to finish three things                                              #\n",
        "# 1. Implement the model improvement                                           #\n",
        "# 2. Draw learning curves                                                      #\n",
        "# 3. Evaluate model performance on test data                                   #\n",
        "# Note: You do not have to put all the codes in this cell and can write in     #\n",
        "# multiple cells.                                                              #\n",
        "################################################################################\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_f8ShJkaD4ja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Transfer Learning (30%)\n",
        "\n",
        "Next, we are going to fine-tune [VGG19](https://arxiv.org/abs/1409.1556) on our small dogs-vs-cats dataset. Specifically, we will load the VGG19 model pre-trained on ImageNet, freeze its weights, add some new layers on top of the frozen layers from VGG19, and train the new layers on our dataset. You need to add an output classification layer on top of the base VGG19 model. Please also add a `Dropout` layer with dropout rate = 0.5 before the classification layer for regularization.\n",
        "\n",
        "**Inline Question #6:** Please implement the transfer learning, draw learning curves, and report model performance on test data.  \n",
        "* Please explain your observation of the learning curves.\n",
        "* What is the model performance on the test data? Is the better than the baseline model? Why is the performance better or worse than before?\n"
      ],
      "metadata": {
        "id": "lA8kr7nhEClq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Your Answer:** *fill this in*"
      ],
      "metadata": {
        "id": "zuwCM1acHjl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "# TODO: Fill in your codes                                                     #\n",
        "# You need to finish three things                                              #\n",
        "# 1. Implement transfer learning: define, configure, and train model           #\n",
        "# 2. Draw learning curves                                                      #\n",
        "# 3. Evaluate model performance on test data                                   #\n",
        "# Note: You do not have to put all the codes in this cell and can write in     #\n",
        "# multiple cells.                                                              #\n",
        "################################################################################\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3nBoDnHrPcmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Winning Model and Model Performance (20%)\n",
        "\n",
        "You probably have noticed that transfer learning achieved a better prediction performance on the test data. In this section, please experiment with more ideas to further improve model performance.\n",
        "\n",
        "When experimenting with different model improvement ideas, please only use training and validation data. After you selecting a winning model based on its performance on the validation data, evaluate the winning model's performance on the test data and report it here.\n",
        "\n",
        "Note that this section is worth 20% of your total grade. Half of it (i.e., 10%) is based on implementation (i.e., implement one improvement) and the other half is based on performance. Teams with higher performance scores get higher grade.\n",
        "\n",
        "If you experiment with more than one idea, you do not need to submit all experiment codes and results but just the winning one. You can definitely talk about them in the answers below.\n",
        "\n",
        "\n",
        "**Inline Question #7:** How would you improve the model performance further?  \n",
        "* What did you try and what did you find?\n",
        "* What is the rational behind the winning model?\n",
        "* What is the winning model's performance on the test data?"
      ],
      "metadata": {
        "id": "xGYrNIm_JZhb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "# TODO: Fill in your codes                                                     #\n",
        "# You need to include three things                                             #\n",
        "# 1. Implement one improvement of the model                                    #\n",
        "# 2. Draw learning curves                                                      #\n",
        "# 3. Evaluate model performance on test data                                   #\n",
        "# Note: You do not have to put all the codes in this cell and can write in     #\n",
        "# multiple cells.                                                              #\n",
        "################################################################################\n"
      ],
      "metadata": {
        "id": "NtxDwc3fJet6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hints to Improve Model Performance\n",
        "\n",
        "\n",
        "*   Try different batch_size and num_epochs\n",
        "*   Try batch normalization, dropout, regularization (check textbook DIL Chapter 9 \"Unstable Gradients\", \"Modern Generalization\")\n",
        "*   Try different optimzers, learning_rate (e.g., learning rate decay, check textbook DIL Chapter 9 \"Fancy Optimizers\")\n",
        "*   Try data augmentation using ImageDataGenerator (check textbook DIL Chapter 9 \"Data Augmentation\" and Chapter 10 Example 10.8)\n",
        "*   Try different pre-trained models (check https://keras.io/api/applications/)\n",
        "*   Try a round of fine-tuning of the entire model instead of just the final classification layer (check https://keras.io/guides/transfer_learning/#the-typical-transferlearning-workflow)\n",
        "*   You probably need to use `tf.keras.callbacks.ModelCheckpoint` and `tf.keras.callbacks.EarlyStopping` to help decide when to stop training and store the best model. https://keras.io/api/callbacks/\n",
        "\n"
      ],
      "metadata": {
        "id": "OGt8UnxfOVP5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qS0NBWAha8UL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
